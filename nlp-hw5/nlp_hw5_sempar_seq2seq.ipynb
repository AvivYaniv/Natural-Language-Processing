{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_hw5_sempar_seq2seq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWgkabpzFCkQ",
        "colab_type": "text"
      },
      "source": [
        "# Semantic Parsing with Sequence to Sequence Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2ez_GsjFPse",
        "colab_type": "text"
      },
      "source": [
        "In this assignment we will use sequence to sequence (seq2seq) models to tackle a semantic parsing dataset. We will implement increasingly complex models and observe their increasingly better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1xUCYzadwwN",
        "colab_type": "text"
      },
      "source": [
        "## Dataset\n",
        "We will use the geoqueries880 dataset. The original dataset can be found [here](https://www.cs.utexas.edu/users/ml/nldata/geoquery.html), but we will use the version from Data Recombination for Neural Semantic Parsing [(Jia & Liang, 2016)](https://stanford.edu/~robinjia/pdf/jia2016recombination.pdf). The relevant dataset files can be found in the assignment zip.\n",
        "\n",
        "As a semantic parsing dataset, geo880 maps natural language sentences to their 'logical form', which in our case is a query string to be fed to a database.\n",
        "\n",
        "### Sample training example\n",
        "natural language sentence:  \n",
        "`what states border kentucky ?`  \n",
        "logical form (query string):  \n",
        "`_answer ( A , ( _state ( A ) , _next_to ( A , B ) , _const ( B , _stateid ( kentucky ) ) ) )`\n",
        "\n",
        "The result of feeding the query string into the database is called the \"execution\". For example, the execution of the above query string could be:  \n",
        "`indiana, ohio, west viginia, virginia, tennessee, missouri, illinois`\n",
        "\n",
        "Recall from class that mapping between natural sentences and executions (as opposed to logical forms) is known as \"weak supervision\" (or \"light supervision\"). For simplicity, we will ignore the execution part, and map between natural sentences and query strings, as in our version of geo880. This is known as \"strong supervision\" (or, as referred to in the lecture slides, \"heavy supervision\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adGQ1PzqvPQV",
        "colab_type": "text"
      },
      "source": [
        "## Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TPE10PivHqf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LOAwYWCvz1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For reproducibility\n",
        "def set_random_seeds():\n",
        "    torch.manual_seed(1407)\n",
        "    random.seed(1411)\n",
        "    np.random.seed(1710)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9g21lLptynw",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing\n",
        "Before implementing the seq2seq models, we first need to prepare our data. We have already implemented utilities for this end, albeit simple ones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUY-bpNayaWQ",
        "colab_type": "text"
      },
      "source": [
        "### Helper utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCqotH_vuDXU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_IDX = 0\n",
        "SOS_STR = '<SOS>'\n",
        "EOS_IDX = 1\n",
        "EOS_STR = '<EOS>'\n",
        "UNK_IDX = 2\n",
        "UNK_STR = '<UNK>'\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, sentences, name, unk_threshold=1):\n",
        "        self.name = name\n",
        "        self.unk_threshold = unk_threshold\n",
        "\n",
        "        self.word_counts = Counter()\n",
        "        self.i2t = {SOS_IDX: SOS_STR, EOS_IDX: EOS_STR, UNK_IDX: UNK_STR}\n",
        "        self.t2i = None\n",
        "        self._parallel_index_mapping = None\n",
        "\n",
        "        self._count_words(sentences)\n",
        "        self._create_token_mappings()\n",
        "\n",
        "    def _count_words(self, sentences):\n",
        "        for sentence in sentences:\n",
        "            self.word_counts.update(sentence.split(' '))\n",
        "\n",
        "    def _create_token_mappings(self):\n",
        "        n_fixed_tokens = len(self.i2t)\n",
        "        words_above_threshold = [word for word, count in self.word_counts.items()\n",
        "                                 if count > self.unk_threshold]\n",
        "        self.i2t.update(enumerate(words_above_threshold, start=n_fixed_tokens))\n",
        "        self.t2i = {index: token for token, index in self.i2t.items()}\n",
        "        self.n_tokens = len(self.t2i)\n",
        "\n",
        "    def set_parallel_vocab(self, other_vocab):  # only relevant for the copying model\n",
        "\n",
        "        parallel_index_mapping = {}\n",
        "        for other_token in other_vocab.t2i:\n",
        "            if other_token in self.t2i:\n",
        "                parallel_index_mapping[other_vocab.t2i[other_token]] = self.t2i[other_token]\n",
        "        self._parallel_index_mapping = parallel_index_mapping\n",
        "\n",
        "    def get_index_from_parallel_index(self, parallel_index):  # for use with the copying model\n",
        "        \"\"\"\n",
        "        given an index `parallel_index` from a another vocab, returns the this vocab's index of the\n",
        "        corresponding token.\n",
        "\n",
        "        For example, if vocab_logical has the token 'kentucky' mapped to index 10, and vocab_natural\n",
        "        has the token kentucky mapped to index 20, then if self=vocab_logical, we get\n",
        "        get_index_from_parallel_index(20) returns 10.\n",
        "\n",
        "        This method should only be used after a call to set_parallel_vocab was\n",
        "        previously made.\n",
        "        \"\"\"\n",
        "        return self._parallel_index_mapping.get(parallel_index, UNK_IDX)\n",
        "\n",
        "    def sentence_to_tensor(self, sentence):\n",
        "        words = sentence.split(' ')\n",
        "        indices = [self.t2i.get(word, self.t2i[UNK_STR]) for word in words]\n",
        "        indices.append(self.t2i[EOS_STR])\n",
        "        return torch.tensor(indices, dtype=torch.long, device=device).view(-1, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBJ7fXIuyRLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _load_sentence_pairs(path):\n",
        "    with open(path) as f:\n",
        "        lines = f.read().strip().split('\\n')\n",
        "    pairs = [[s for s in l.split('\\t')] for l in lines]\n",
        "    return pairs\n",
        "\n",
        "\n",
        "def _create_vocabs(pairs, unk_threshold=1):\n",
        "    print(\"Creating vocabularies...\")\n",
        "    natural_sentences, logical_sentences = zip(*pairs)\n",
        "\n",
        "    vocab_natural = Vocab(natural_sentences, 'natural', unk_threshold)\n",
        "    vocab_logical = Vocab(logical_sentences, 'logical', unk_threshold)\n",
        "\n",
        "    print(f'# natural tokens: {vocab_natural.n_tokens}')\n",
        "    print(f'# logical tokens: {vocab_logical.n_tokens}')\n",
        "\n",
        "    return vocab_natural, vocab_logical\n",
        "\n",
        "\n",
        "def load_data(train_path, dev_path):\n",
        "    train_sentences = _load_sentence_pairs(train_path)\n",
        "\n",
        "    vocab_natural, vocab_logical = _create_vocabs(train_sentences)\n",
        "\n",
        "    dev_sentences = _load_sentence_pairs(dev_path)\n",
        "\n",
        "    return train_sentences, dev_sentences, vocab_natural, vocab_logical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9IjiiqzxfdK",
        "colab_type": "text"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GYYOsF5y25q",
        "colab_type": "text"
      },
      "source": [
        "To load the data, we need access to the dataset files. Define a root directory below, where the dataset files will be uploaded into a `data/` directory. As files uploaded using \"Upload\" are deleted after a while, consider using the \"Mount Drive\" option and uploading the dataset files directly to your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF4ivrYj0eOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# redefine ROOT_DIR as you wish\n",
        "import os\n",
        "ROOT_DIR = os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqyAaJUHyqsf",
        "colab_type": "code",
        "outputId": "34e58ef7-8174-4356-f9c5-2601611adc46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "TRAIN_SET_PATH = os.path.join(ROOT_DIR, \"geo880_train500.tsv\")\n",
        "DEV_SET_PATH = os.path.join(ROOT_DIR, \"geo880_dev100.tsv\")\n",
        "\n",
        "train_sentences, dev_sentences, vocab_natural, vocab_logical = load_data(TRAIN_SET_PATH, DEV_SET_PATH)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating vocabularies...\n",
            "# natural tokens: 184\n",
            "# logical tokens: 118\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN7hrxpc3FnI",
        "colab_type": "text"
      },
      "source": [
        "Below is a random example from `train_sentences` and `dev_sentences`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DrUi1Xy3VxB",
        "colab_type": "code",
        "outputId": "221f009f-f5ad-47a0-a2c6-5ee245aa2bd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(f'training example:\\n{random.choice(train_sentences)}')\n",
        "print()\n",
        "print(f'dev example:\\n{random.choice(dev_sentences)}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training example:\n",
            "['in which state does the highest point in usa exist ?', '_answer ( A , ( _loc ( B , A ) , _state ( A ) , _highest ( B , ( _place ( B ) , _loc ( B , C ) , _const ( C , _countryid ( usa ) ) ) ) ) )']\n",
            "\n",
            "dev example:\n",
            "['how big is the city of new york ?', \"_answer ( A , ( _size ( B , A ) , _const ( B , _cityid ( ' new york ' , _ ) ) ) )\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF2GBWWX383G",
        "colab_type": "text"
      },
      "source": [
        "As you can see, each example is a list of length 2 where the first element is a natural language sentence and the second element is its corresponding query string. In both sentences, all words are separated by a space.\n",
        "\n",
        "The `Vocab` objects, `vocab_natural` and `vocab_logical`, each represent a vocabulary of tokens from the corresponding 'natural language' and 'query string' domains. When creating the vocabularies, each word that occurrs less than 2 times (`unk_threshold=1`) in the training set is considered an unknown (`<UNK>`) token. Note that even though there are shared tokens between them, each vocabulary was created based on a single domain (natural/query)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TWsicCp6CvE",
        "colab_type": "text"
      },
      "source": [
        "### 'Special' strings in the logical domain\n",
        "observe the query string from the following training example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpqiDqdt6ZTl",
        "colab_type": "code",
        "outputId": "599c0864-5b30-43ca-ab60-d95da5d6d398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(train_sentences[24])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['what is the highest elevation in south carolina ?', \"_answer ( A , _highest ( A , ( _place ( A ) , _loc ( A , B ) , _const ( B , _stateid ( ' south carolina ' ) ) ) ) )\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDSqdYPg6po8",
        "colab_type": "text"
      },
      "source": [
        "Note that ` ' south carolina ' ` could be seen as a single logical token, just like `kentucky`. However, in our simple tokenization scheme, this word is tokenized into 4 different tokens: `'`, `south`, `carolina` and `'`. This hurts performance, but will probably make the implementation in later stages easier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAx86KpK8He8",
        "colab_type": "text"
      },
      "source": [
        "## Simple Seq2seq Model\n",
        "In this part we will implement a simple encoder-decoder model, similar to v1.0 from class. In addition to the class slides, a good reference material for seq2seq models is [Jay Alammar](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/). It contains helpful animations explaining our v1.0 seq2seq model, in addition to the v2.0 model (attention) that we will implement later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VqPq43H9Q9m",
        "colab_type": "text"
      },
      "source": [
        "### Encoder\n",
        "Our encoder is very simple, using a [GRU](https://pytorch.org/docs/stable/nn.html#gru) to encode the natural language sentence. Note that the `input_size` parameter of the `GRU` is not the length of the input, but the dimension of the input vector at every timestep."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMiHRC1D-u8N",
        "colab_type": "text"
      },
      "source": [
        "### Question 1.1\n",
        "Implement the `forward` method of `EncoderRNN`.  \n",
        "To implement, just pass the embedded input through the GRU and return the output and the hidden state. You can use the class slides and Jay Alammar as a reference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdkLejDn9f9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, vocab):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab = vocab\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab.n_tokens, hidden_size)\n",
        "        self.gru = nn.GRU(input_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, h_0):\n",
        "        ### YOUR CODE HERE\n",
        "        embedded    = self.embedding(input)\n",
        "        x           = embedded\n",
        "        output, h_0 = self.gru(x, h_0)\n",
        "        ### --------------\n",
        "        return output, h_0\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Etlzvi8T_S8X",
        "colab_type": "text"
      },
      "source": [
        "### Simple decoder\n",
        "Unlike the encoder, our decoder uses a [GRUCell](https://pytorch.org/docs/stable/nn.html#grucell) and not a GRU. This is because while decoding, we want to be able to control the input of the decoder in each timestep (e.g. [\"teacher forcing\"](https://towardsdatascience.com/what-is-teacher-forcing-3da6217fed1c)).  \n",
        "In addition, there are two additional parameter matrices in `DecoderSimple`.  \n",
        "The first is `W_p`, and is used to project the last hidden state of the encoder to the decoder space, as the their hidden dimensions are not necessarily equal (albeit in our case they _are_ equal).  \n",
        "The second is `W_s`, and is used as $W^{(s)}$ from class.  \n",
        "You can ignore the `uses_copying` attribute, as it will only be relevant in question 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJI1_Fe1EZbR",
        "colab_type": "text"
      },
      "source": [
        "### Question 1.2\n",
        "Implement the `forward` method of `DecoderSimple`.  \n",
        " You can use the class slides and Jay Alammar as a reference.  \n",
        "Don't forget to address the `evaluation_mode` parameter, as the input to `GRUCell` could depend on whether we are training or evaluating. It is your choice if and how to use teacher forcing during training, but at least some usage of teacher forcing is highly recommended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEnQtakP_euX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderSimple(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, vocab, **kwargs):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.vocab = vocab\n",
        "        self.output_size = self.vocab.n_tokens\n",
        "\n",
        "        self.uses_copying = False\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "\n",
        "        # for projecting the last hidden state of the encoder to the decoder space,\n",
        "        # as the first decoder hidden state, in case the two dimensions don't match\n",
        "        self.W_p = nn.Linear(enc_hidden_size, hidden_size)\n",
        "\n",
        "        self.gru_cell = nn.GRUCell(self.input_size, self.hidden_size)\n",
        "\n",
        "        # for output\n",
        "        self.W_s = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, targets, h, evaluation_mode=False, **kwargs):\n",
        "        ### YOUR CODE HERE\n",
        "        if evaluation_mode:\n",
        "            use_teacher_forcing     = False\n",
        "        else:\n",
        "            teacher_forcing_ratio   = 0.6\n",
        "            use_teacher_forcing     = True if random.random() < teacher_forcing_ratio else False \n",
        "\n",
        "        batch_size      = h.shape[2]\n",
        "        decoder_input   = self.embedding(torch.tensor([SOS_IDX], device=device))\n",
        "        decoder_hidden  = self.W_p(h).squeeze(0)\n",
        "        \n",
        "        def forward_step(input, hidden):\n",
        "            hidden      = self.gru_cell(input.float(), hidden.float())\n",
        "            output      = self.W_s(hidden)\n",
        "            return output, hidden\n",
        "\n",
        "        outputs = []\n",
        "        targets_embeddings = self.embedding(targets.squeeze())\n",
        "        for t in range(len(targets_embeddings)):\n",
        "            decoder_output_on_t, decoder_hidden = forward_step(decoder_input, decoder_hidden)\n",
        "            outputs.append(decoder_output_on_t)\n",
        "\n",
        "            if use_teacher_forcing:\n",
        "                decoder_input = targets_embeddings[t, :].unsqueeze(0)\n",
        "            else:\n",
        "                decoder_input = decoder_output_on_t.argmax(-1)\n",
        "                decoder_input = self.embedding(decoder_input)                \n",
        "\n",
        "            if evaluation_mode and EOS_IDX == torch.argmax(decoder_output_on_t, dim=1):\n",
        "                break\n",
        "\n",
        "        outputs = torch.cat(outputs)\n",
        "\n",
        "        ### --------------\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfhjamNaHPsc",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "To simplify debugging, we always use a batch size of 1. Note that just as our simple tokenization scheme, using a batch size of 1 (where we could probably train all examples in one batch) will hurt performance.\n",
        "\n",
        "During training, we pass the tokenized natural sentence through the encoder, and pass the final encoder hidden state (as well as additional arguments in later, more complex, models) to the decoder. Then, we use the decoder output the calculate the loss with a `criterion`, and perform backpropagation.\n",
        "\n",
        "Until question 3, you can ignore the `if dec.uses_copying:` condition and assume it is always false. You will implement this part in question 3.2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atqrArR2H6nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_single_example(input_tensor, target_tensor, enc, dec,\n",
        "                         enc_optimizer, dec_optimizer, criterion):\n",
        "    encoder_hidden_first = enc.init_hidden()\n",
        "\n",
        "    enc_optimizer.zero_grad()\n",
        "    dec_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs, encoder_h_m = enc(input_tensor, encoder_hidden_first)\n",
        "\n",
        "    decoder_hidden = encoder_h_m\n",
        "\n",
        "    decoder_outputs = dec(target_tensor, decoder_hidden, enc_input=input_tensor, enc_outputs=encoder_outputs)\n",
        "\n",
        "    if dec.uses_copying:\n",
        "        ### YOUR CODE HERE\n",
        "        raise NotImplementedError\n",
        "        ### --------------\n",
        "    else:\n",
        "        criterion_target = target_tensor.view(-1)\n",
        "\n",
        "    loss = criterion(decoder_outputs, criterion_target)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    enc_optimizer.step()\n",
        "    dec_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HamkvLCsKqdj",
        "colab_type": "text"
      },
      "source": [
        "After each epoch, we can save the current model in the `parameters/` directory using the `save` parameter in `train`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-ZV0QnrLszy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PARAMETERS_DIR = os.path.join(ROOT_DIR, 'parameters')\n",
        "\n",
        "def save_model(enc, dec, epoch, postfix=''):\n",
        "    torch.save(enc, os.path.join(PARAMETERS_DIR, f'enc_{epoch}{postfix}.pt'))\n",
        "    torch.save(dec, os.path.join(PARAMETERS_DIR, f'dec_{epoch}{postfix}.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOE1H2D_T-dI",
        "colab_type": "text"
      },
      "source": [
        "Simple utility functions for printing the status of the training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw_E25wPT8UM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / percent\n",
        "    rs = es - s\n",
        "    return '%s (%s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiLIJtWSMBYc",
        "colab_type": "text"
      },
      "source": [
        "When training, we can use the `patience` parameter to stop the training if our results on the dev set didn't improve for `patience` number of epoch. The default, -1, means training for `n_epochs` regardless of the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrTor1PDKqsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(n_epochs, train_set, dev_set, enc, dec, criterion,\n",
        "          patience=-1, save=True, print_sentences=False):\n",
        "    start = time.time()\n",
        "\n",
        "    train_accuracies = []\n",
        "    losses = []\n",
        "    epoch_loss = 0  # Reset every epoch\n",
        "\n",
        "    dev_accuracies = []\n",
        "    best_dev_accuracy = 0\n",
        "    epochs_without_improvement = 0  # for early stopping (patience)\n",
        "\n",
        "    encoder_optimizer = optim.Adam(enc.parameters())\n",
        "    decoder_optimizer = optim.Adam(dec.parameters())\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        random.shuffle(train_set)\n",
        "\n",
        "        for natural_string, logical_string in train_set:\n",
        "            input_tensor = enc.vocab.sentence_to_tensor(natural_string)\n",
        "            target_tensor = dec.vocab.sentence_to_tensor(logical_string)\n",
        "\n",
        "            loss = train_single_example(input_tensor, target_tensor, enc, dec,\n",
        "                                        encoder_optimizer, decoder_optimizer, criterion)\n",
        "            epoch_loss += loss\n",
        "\n",
        "        average_loss = epoch_loss / len(train_set)\n",
        "        losses.append(average_loss)\n",
        "        epoch_loss = 0\n",
        "\n",
        "        train_accuracy = evaluate(train_set, enc, dec, print_sentences)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        dev_accuracy = evaluate(dev_set, enc, dec, print_sentences)\n",
        "        dev_accuracies.append(dev_accuracy)\n",
        "\n",
        "        print(f'Epoch #{epoch}:\\n'\n",
        "              f'Loss: {average_loss:.4f}\\n'\n",
        "              f'Train accuracy: {train_accuracy:.3f}\\n'\n",
        "              f'Dev accuracy: {dev_accuracy:.3f}\\n'\n",
        "              f'Time elapsed (remaining): {timeSince(start, epoch / n_epochs)}')\n",
        "\n",
        "        if save:\n",
        "            save_model(enc, dec, epoch)\n",
        "\n",
        "        if dev_accuracy > best_dev_accuracy:\n",
        "            best_dev_accuracy = dev_accuracy\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement == patience:\n",
        "                print(f'Training didn\\'t improve for {patience} epochs\\n'\n",
        "                      f'Stopped Training at epoch {epoch}\\n'\n",
        "                      f'Best epoch: {epoch - patience}')\n",
        "                break\n",
        "\n",
        "    return losses, train_accuracies, dev_accuracies"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn36fyCXRZrV",
        "colab_type": "text"
      },
      "source": [
        "### Plotting the accuracies\n",
        "Using the return values of `train`, we can use `plot_accuracies` to create a plot of our performance on the train and dev sets during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGBdUpLOSaKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FIGURES_DIR = os.path.join(ROOT_DIR, 'figures')\n",
        "\n",
        "def plot_accuracies(train_accs, dev_accs, model_name):\n",
        "\n",
        "    plt.clf()\n",
        "    plt.title(model_name)\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "\n",
        "    plt.plot(train_accs, label='train')\n",
        "    plt.plot(dev_accs, label='dev')\n",
        "\n",
        "    plt.xticks(range(len(train_accs)), range(1, len(train_accs) + 1))\n",
        "    plt.yticks(np.around(np.linspace(0.0, 1.0, num=11), decimals=1))\n",
        "\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(FIGURES_DIR, f'{model_name}.png'))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B7xG0KQOC_H",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "When evaluating, we perform a procedure similar to training, with the following differences:  \n",
        "* We do not perform backpropagation or compute gradients.\n",
        "* At each timestep of the decoder, the input is determined by the `if evaluation_mode:` clause of the `forward` method in the previous timestep (recall Question 1.2). In class, we saw using the most probable token (argmax) from the output of the previous timestep as an input of the current timestep.\n",
        "* The outputs of the decoder, containing indices of the predicted tokens, are transformed into strings to create the predicted query string.\n",
        "\n",
        "Our evaluation metric is \"exact match\": a prediction is correct only if it is identical to the target query string.\n",
        "\n",
        "Until question 3, you can ignore the `if dec.uses_copying:` condition and assume it is always false. You will implement this part in question 3.3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGU2H__DOFvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(sentences, enc, dec, print_sentences=True):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for pair in sentences:\n",
        "            input_sentence, target_sentence = pair\n",
        "            input_tensor = enc.vocab.sentence_to_tensor(input_sentence)\n",
        "            target_tensor = dec.vocab.sentence_to_tensor(target_sentence)\n",
        "\n",
        "            encoder_hidden_first = enc.init_hidden()\n",
        "\n",
        "            encoder_outputs, encoder_h_m = enc(input_tensor, encoder_hidden_first)\n",
        "\n",
        "            decoder_hidden = encoder_h_m\n",
        "\n",
        "            decoder_outputs = dec(target_tensor, decoder_hidden,\n",
        "                                  enc_outputs=encoder_outputs, enc_input=input_tensor,\n",
        "                                  evaluation_mode=True)\n",
        "            decoded_indices = torch.argmax(decoder_outputs, dim=1)\n",
        "\n",
        "            if dec.uses_copying:\n",
        "                ### YOUR CODE HERE\n",
        "                raise NotImplementedError\n",
        "                ### --------------\n",
        "\n",
        "            else:\n",
        "                decoded_tokens = [dec.vocab.i2t[idx.item()] for idx in decoded_indices]\n",
        "\n",
        "            decoded_sentence = ' '.join(decoded_tokens[:-1])  # ignore the EOS token\n",
        "\n",
        "            if decoded_sentence == target_sentence:\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "            if print_sentences:\n",
        "                print(f'input:    {input_sentence}')\n",
        "                print(f'expected: {target_sentence}')\n",
        "                print(f'result:   {decoded_sentence}')\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2NexHdXSoyH",
        "colab_type": "text"
      },
      "source": [
        "### Testing Question 1\n",
        "To test your implementation of the simple model, you can run the following two cells. **Make sure to use the GPU and not the CPU: `Runtime`->`Change runtime type`->`Hardware accelerator`->`GPU`**.  \n",
        "\n",
        "Note that we expect a dev accuracy of at least 35 sometime until epoch 40 (could be a lot earlier). Your code will be run with several initial seeds, and therefore the 35 dev accuracy is expected on average.  \n",
        "Use the `nn.CrossEntropyLoss` criterion.\n",
        "\n",
        "To compare implementations during debugging, you can use the `set_random_seeds()` function.\n",
        "\n",
        "**Add the output figure, `ROOT/figures/simple_decoder.png`, to the submission zip!** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2zy_W_qVCR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# general settings, to be used with all the models\n",
        "enc_input_size = 256\n",
        "enc_hidden_size = 256\n",
        "\n",
        "dec_input_size = 256\n",
        "dec_hidden_size = 256\n",
        "\n",
        "n_epochs = 40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J473umolVHVE",
        "colab_type": "code",
        "outputId": "b462c455-e685-4616-8c64-bfde23d4608d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# print('--- Training Simple Model ---')\n",
        "enc1 = EncoderRNN(enc_input_size, enc_hidden_size, vocab_natural).to(device)\n",
        "dec1 = DecoderSimple(dec_input_size, dec_hidden_size, vocab_logical).to(device)\n",
        "criterion1 = nn.CrossEntropyLoss()\n",
        "\n",
        "losses1, train_accs1, dev_accs1 = train(n_epochs, train_sentences, dev_sentences,\n",
        "                                        enc1, dec1, criterion1)\n",
        "plot_accuracies(train_accs1, dev_accs1, 'simple_decoder')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #1:\n",
            "Loss: 0.0482\n",
            "Train accuracy: 0.004\n",
            "Dev accuracy: 0.000\n",
            "Time elapsed (remaining): 0m 35s (22m 47s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type DecoderSimple. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch #2:\n",
            "Loss: 0.0280\n",
            "Train accuracy: 0.012\n",
            "Dev accuracy: 0.000\n",
            "Time elapsed (remaining): 1m 8s (21m 49s)\n",
            "Epoch #3:\n",
            "Loss: 0.0268\n",
            "Train accuracy: 0.020\n",
            "Dev accuracy: 0.010\n",
            "Time elapsed (remaining): 1m 43s (21m 12s)\n",
            "Epoch #4:\n",
            "Loss: 0.0201\n",
            "Train accuracy: 0.032\n",
            "Dev accuracy: 0.040\n",
            "Time elapsed (remaining): 2m 17s (20m 37s)\n",
            "Epoch #5:\n",
            "Loss: 0.0191\n",
            "Train accuracy: 0.114\n",
            "Dev accuracy: 0.070\n",
            "Time elapsed (remaining): 2m 51s (20m 0s)\n",
            "Epoch #6:\n",
            "Loss: 0.0157\n",
            "Train accuracy: 0.110\n",
            "Dev accuracy: 0.080\n",
            "Time elapsed (remaining): 3m 25s (19m 25s)\n",
            "Epoch #7:\n",
            "Loss: 0.0155\n",
            "Train accuracy: 0.160\n",
            "Dev accuracy: 0.080\n",
            "Time elapsed (remaining): 4m 0s (18m 53s)\n",
            "Epoch #8:\n",
            "Loss: 0.0144\n",
            "Train accuracy: 0.194\n",
            "Dev accuracy: 0.140\n",
            "Time elapsed (remaining): 4m 35s (18m 21s)\n",
            "Epoch #9:\n",
            "Loss: 0.0128\n",
            "Train accuracy: 0.210\n",
            "Dev accuracy: 0.150\n",
            "Time elapsed (remaining): 5m 10s (17m 48s)\n",
            "Epoch #10:\n",
            "Loss: 0.0123\n",
            "Train accuracy: 0.250\n",
            "Dev accuracy: 0.130\n",
            "Time elapsed (remaining): 5m 44s (17m 12s)\n",
            "Epoch #11:\n",
            "Loss: 0.0095\n",
            "Train accuracy: 0.278\n",
            "Dev accuracy: 0.170\n",
            "Time elapsed (remaining): 6m 18s (16m 38s)\n",
            "Epoch #12:\n",
            "Loss: 0.0103\n",
            "Train accuracy: 0.262\n",
            "Dev accuracy: 0.170\n",
            "Time elapsed (remaining): 6m 53s (16m 4s)\n",
            "Epoch #13:\n",
            "Loss: 0.0113\n",
            "Train accuracy: 0.334\n",
            "Dev accuracy: 0.130\n",
            "Time elapsed (remaining): 7m 27s (15m 29s)\n",
            "Epoch #14:\n",
            "Loss: 0.0090\n",
            "Train accuracy: 0.424\n",
            "Dev accuracy: 0.170\n",
            "Time elapsed (remaining): 8m 1s (14m 54s)\n",
            "Epoch #15:\n",
            "Loss: 0.0065\n",
            "Train accuracy: 0.466\n",
            "Dev accuracy: 0.240\n",
            "Time elapsed (remaining): 8m 35s (14m 19s)\n",
            "Epoch #16:\n",
            "Loss: 0.0063\n",
            "Train accuracy: 0.528\n",
            "Dev accuracy: 0.220\n",
            "Time elapsed (remaining): 9m 10s (13m 45s)\n",
            "Epoch #17:\n",
            "Loss: 0.0058\n",
            "Train accuracy: 0.578\n",
            "Dev accuracy: 0.200\n",
            "Time elapsed (remaining): 9m 44s (13m 10s)\n",
            "Epoch #18:\n",
            "Loss: 0.0062\n",
            "Train accuracy: 0.506\n",
            "Dev accuracy: 0.210\n",
            "Time elapsed (remaining): 10m 18s (12m 35s)\n",
            "Epoch #19:\n",
            "Loss: 0.0062\n",
            "Train accuracy: 0.570\n",
            "Dev accuracy: 0.260\n",
            "Time elapsed (remaining): 10m 52s (12m 1s)\n",
            "Epoch #20:\n",
            "Loss: 0.0062\n",
            "Train accuracy: 0.506\n",
            "Dev accuracy: 0.190\n",
            "Time elapsed (remaining): 11m 26s (11m 26s)\n",
            "Epoch #21:\n",
            "Loss: 0.0040\n",
            "Train accuracy: 0.692\n",
            "Dev accuracy: 0.230\n",
            "Time elapsed (remaining): 12m 0s (10m 51s)\n",
            "Epoch #22:\n",
            "Loss: 0.0060\n",
            "Train accuracy: 0.696\n",
            "Dev accuracy: 0.270\n",
            "Time elapsed (remaining): 12m 34s (10m 17s)\n",
            "Epoch #23:\n",
            "Loss: 0.0043\n",
            "Train accuracy: 0.770\n",
            "Dev accuracy: 0.330\n",
            "Time elapsed (remaining): 13m 8s (9m 42s)\n",
            "Epoch #24:\n",
            "Loss: 0.0038\n",
            "Train accuracy: 0.756\n",
            "Dev accuracy: 0.290\n",
            "Time elapsed (remaining): 13m 42s (9m 8s)\n",
            "Epoch #25:\n",
            "Loss: 0.0037\n",
            "Train accuracy: 0.726\n",
            "Dev accuracy: 0.360\n",
            "Time elapsed (remaining): 14m 17s (8m 34s)\n",
            "Epoch #26:\n",
            "Loss: 0.0033\n",
            "Train accuracy: 0.748\n",
            "Dev accuracy: 0.290\n",
            "Time elapsed (remaining): 14m 52s (8m 0s)\n",
            "Epoch #27:\n",
            "Loss: 0.0025\n",
            "Train accuracy: 0.744\n",
            "Dev accuracy: 0.300\n",
            "Time elapsed (remaining): 15m 26s (7m 26s)\n",
            "Epoch #28:\n",
            "Loss: 0.0038\n",
            "Train accuracy: 0.764\n",
            "Dev accuracy: 0.320\n",
            "Time elapsed (remaining): 16m 0s (6m 51s)\n",
            "Epoch #29:\n",
            "Loss: 0.0057\n",
            "Train accuracy: 0.714\n",
            "Dev accuracy: 0.300\n",
            "Time elapsed (remaining): 16m 35s (6m 17s)\n",
            "Epoch #30:\n",
            "Loss: 0.0039\n",
            "Train accuracy: 0.722\n",
            "Dev accuracy: 0.300\n",
            "Time elapsed (remaining): 17m 9s (5m 43s)\n",
            "Epoch #31:\n",
            "Loss: 0.0049\n",
            "Train accuracy: 0.798\n",
            "Dev accuracy: 0.280\n",
            "Time elapsed (remaining): 17m 43s (5m 8s)\n",
            "Epoch #32:\n",
            "Loss: 0.0021\n",
            "Train accuracy: 0.808\n",
            "Dev accuracy: 0.320\n",
            "Time elapsed (remaining): 18m 17s (4m 34s)\n",
            "Epoch #33:\n",
            "Loss: 0.0013\n",
            "Train accuracy: 0.870\n",
            "Dev accuracy: 0.310\n",
            "Time elapsed (remaining): 18m 52s (4m 0s)\n",
            "Epoch #34:\n",
            "Loss: 0.0027\n",
            "Train accuracy: 0.830\n",
            "Dev accuracy: 0.320\n",
            "Time elapsed (remaining): 19m 26s (3m 25s)\n",
            "Epoch #35:\n",
            "Loss: 0.0031\n",
            "Train accuracy: 0.774\n",
            "Dev accuracy: 0.260\n",
            "Time elapsed (remaining): 20m 0s (2m 51s)\n",
            "Epoch #36:\n",
            "Loss: 0.0035\n",
            "Train accuracy: 0.750\n",
            "Dev accuracy: 0.280\n",
            "Time elapsed (remaining): 20m 34s (2m 17s)\n",
            "Epoch #37:\n",
            "Loss: 0.0031\n",
            "Train accuracy: 0.640\n",
            "Dev accuracy: 0.280\n",
            "Time elapsed (remaining): 21m 8s (1m 42s)\n",
            "Epoch #38:\n",
            "Loss: 0.0056\n",
            "Train accuracy: 0.776\n",
            "Dev accuracy: 0.290\n",
            "Time elapsed (remaining): 21m 42s (1m 8s)\n",
            "Epoch #39:\n",
            "Loss: 0.0032\n",
            "Train accuracy: 0.780\n",
            "Dev accuracy: 0.310\n",
            "Time elapsed (remaining): 22m 17s (0m 34s)\n",
            "Epoch #40:\n",
            "Loss: 0.0029\n",
            "Train accuracy: 0.814\n",
            "Dev accuracy: 0.330\n",
            "Time elapsed (remaining): 22m 51s (0m 0s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Exq6p6XtXJvH",
        "colab_type": "text"
      },
      "source": [
        "## Improving the Simple Model\n",
        "\n",
        "We can improve this simple model in various ways, many of them are very simple:  \n",
        "\n",
        "* Using a bidirectional GRU in the encoder instead of a unidirectional one.\n",
        "* Using stack RNNs.\n",
        "* Using pretrained embeddings, such as GloVe, Instead of our randomly initialized embeddings.\n",
        "* Using [dropout](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/). It is especially beneficial with small datasets, like ours. \n",
        "* Decoding with beam search.\n",
        "* Larger batch size and better tokenization, as we already mentioned.\n",
        "\n",
        "In this assignment, we won't use any of those. Instead, we will implement an attention mechanism as we saw in class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4ORq7MKaOuq",
        "colab_type": "text"
      },
      "source": [
        "## Attention Seq2seq Model\n",
        "In this part we will introduce attention to our model, and implement a model like the one we saw in class. In this v2.0 model we will use the same encoder, so we'll just implement an improved decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBvVh5AhbdcK",
        "colab_type": "text"
      },
      "source": [
        "### Question 2\n",
        "Implement the `forward` method of `DecoderAttention`. You can copy parts of your code from the `forward` method of `DecoderSimple`.\n",
        " Note that there is no single canonical implementation of attention in seq2seq. You can take inspiration from the class slides, from Jay Alammar, or from any source of your choosing. But you have to utilize the encoder outputs at each timestep of the decoder.\n",
        " \n",
        "Don't forget to address the `evaluation_mode` parameter, as the input to `GRUCell` could depend on whether we are training or evaluating. It is your choice if and how to use teacher forcing during training, but at least some usage of teacher forcing is highly recommended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceTj8ATUcnb6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderAttention(DecoderSimple):\n",
        "    def __init__(self, input_size, hidden_size, vocab, enc_hidden_size, **kwargs):\n",
        "        super().__init__(input_size, hidden_size, vocab, **kwargs)\n",
        "\n",
        "        # for attention\n",
        "        self.enc_hidden_size = enc_hidden_size\n",
        "        self.W_a = nn.Linear(self.enc_hidden_size, self.hidden_size)\n",
        "\n",
        "        # for output\n",
        "        self.W_s = nn.Linear(self.hidden_size + self.enc_hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, targets, h, enc_outputs, evaluation_mode=False, **kwargs):\n",
        "\n",
        "        ### YOUR CODE HERE\n",
        "        \n",
        "        if evaluation_mode:\n",
        "            use_teacher_forcing     = False\n",
        "        else:\n",
        "            teacher_forcing_ratio   = 0.25\n",
        "            use_teacher_forcing     = True if random.random() < teacher_forcing_ratio else False \n",
        "\n",
        "        batch_size      = h.shape[2]\n",
        "        decoder_input   = self.embedding(torch.tensor([SOS_IDX], device=device))\n",
        "        decoder_hidden  = self.W_p(h).squeeze(0)\n",
        "                \n",
        "        def forward_step(input, hidden, enc_outputs):\n",
        "            def dot_score(hidden, encoder_output):\n",
        "                return torch.sum(hidden * encoder_output, dim=2)\n",
        "\n",
        "            def calc_attention_weights(hidden, enc_outputs):\n",
        "                enc_outputs     = self.W_a(enc_outputs)\n",
        "                attn_energies   = dot_score(hidden, enc_outputs)\n",
        "                attn_energies   = attn_energies.t()\n",
        "                attn_weights    = F.softmax(attn_energies, dim=1).unsqueeze(1)\n",
        "                return attn_weights\n",
        "            \n",
        "            gru_hidden          = self.gru_cell(input.float(), hidden.float())\n",
        "            attn_weights        = calc_attention_weights(gru_hidden, enc_outputs)\n",
        "            context             = attn_weights.bmm(enc_outputs.transpose(0, 1))\n",
        "            \n",
        "            gru_hidden_copy     = gru_hidden\n",
        "\n",
        "            gru_hidden_copy     = gru_hidden_copy.squeeze(0)\n",
        "            context             = context.squeeze(1)\n",
        "            concat_input        = torch.cat((gru_hidden_copy, context.squeeze()))\n",
        "\n",
        "            concat_output       = concat_input\n",
        "            attention_output    = self.W_s(concat_output)\n",
        "            attention_output    = attention_output.unsqueeze(0)\n",
        "            \n",
        "            return attention_output, gru_hidden\n",
        "\n",
        "        outputs = []\n",
        "        targets_embeddings = self.embedding(targets.squeeze())\n",
        "        for t in range(len(targets_embeddings)):\n",
        "            decoder_output_on_t, decoder_hidden = forward_step(decoder_input, decoder_hidden, enc_outputs)\n",
        "            outputs.append(decoder_output_on_t)\n",
        "            \n",
        "            if use_teacher_forcing:\n",
        "                decoder_input = targets_embeddings[t, :].unsqueeze(0)\n",
        "            else:\n",
        "                decoder_input = decoder_output_on_t.argmax(-1)\n",
        "                decoder_input = self.embedding(decoder_input)                \n",
        "                \n",
        "            if evaluation_mode and EOS_IDX == torch.argmax(decoder_output_on_t, dim=1):\n",
        "                break\n",
        "\n",
        "        outputs = torch.cat(outputs)\n",
        "\n",
        "        ### --------------\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyYrNgOLv0LO",
        "colab_type": "text"
      },
      "source": [
        "### Testing Question 2\n",
        "To test your implementation of the attention model, you can run the following cell. Note that we expect a dev accuracy of at least 40 sometime until epoch 40 (could be a lot earlier). Your code will be run with several initial seeds, and therefore the 40 dev accuracy is expected on average.  \n",
        "Use the `nn.CrossEntropyLoss` criterion.\n",
        "\n",
        "To compare implementations during debugging, you can use the `set_random_seeds()` function.\n",
        "\n",
        "**Add the output figure, `ROOT/figures/attention_decoder.png`, to the submission zip!** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bf78m56wX3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ca37c863-1a0f-47ed-b420-988612acd347"
      },
      "source": [
        "print('--- Training Attention Model ---')\n",
        "enc2 = EncoderRNN(enc_input_size, enc_hidden_size, vocab_natural).to(device)\n",
        "dec2 = DecoderAttention(dec_input_size, dec_hidden_size, vocab_logical, enc_hidden_size).to(device)\n",
        "criterion2 = nn.CrossEntropyLoss()\n",
        "\n",
        "losses2, train_accs2, dev_accs2 = train(n_epochs, train_sentences, dev_sentences,\n",
        "                                        enc2, dec2, criterion2)\n",
        "plot_accuracies(train_accs2, dev_accs2, 'attention_decoder')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Training Attention Model ---\n",
            "Epoch #1:\n",
            "Loss: 0.0567\n",
            "Train accuracy: 0.010\n",
            "Dev accuracy: 0.010\n",
            "Time elapsed (remaining): 1m 12s (47m 7s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type EncoderRNN. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type DecoderAttention. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch #2:\n",
            "Loss: 0.0344\n",
            "Train accuracy: 0.248\n",
            "Dev accuracy: 0.130\n",
            "Time elapsed (remaining): 2m 16s (43m 18s)\n",
            "Epoch #3:\n",
            "Loss: 0.0295\n",
            "Train accuracy: 0.342\n",
            "Dev accuracy: 0.170\n",
            "Time elapsed (remaining): 3m 18s (40m 53s)\n",
            "Epoch #4:\n",
            "Loss: 0.0203\n",
            "Train accuracy: 0.404\n",
            "Dev accuracy: 0.230\n",
            "Time elapsed (remaining): 4m 17s (38m 40s)\n",
            "Epoch #5:\n",
            "Loss: 0.0205\n",
            "Train accuracy: 0.406\n",
            "Dev accuracy: 0.180\n",
            "Time elapsed (remaining): 5m 14s (36m 38s)\n",
            "Epoch #6:\n",
            "Loss: 0.0150\n",
            "Train accuracy: 0.388\n",
            "Dev accuracy: 0.210\n",
            "Time elapsed (remaining): 6m 8s (34m 46s)\n",
            "Epoch #7:\n",
            "Loss: 0.0146\n",
            "Train accuracy: 0.414\n",
            "Dev accuracy: 0.210\n",
            "Time elapsed (remaining): 7m 2s (33m 10s)\n",
            "Epoch #8:\n",
            "Loss: 0.0145\n",
            "Train accuracy: 0.396\n",
            "Dev accuracy: 0.170\n",
            "Time elapsed (remaining): 7m 56s (31m 44s)\n",
            "Epoch #9:\n",
            "Loss: 0.0151\n",
            "Train accuracy: 0.510\n",
            "Dev accuracy: 0.260\n",
            "Time elapsed (remaining): 8m 48s (30m 21s)\n",
            "Epoch #10:\n",
            "Loss: 0.0105\n",
            "Train accuracy: 0.498\n",
            "Dev accuracy: 0.260\n",
            "Time elapsed (remaining): 9m 41s (29m 3s)\n",
            "Epoch #11:\n",
            "Loss: 0.0117\n",
            "Train accuracy: 0.572\n",
            "Dev accuracy: 0.300\n",
            "Time elapsed (remaining): 10m 33s (27m 50s)\n",
            "Epoch #12:\n",
            "Loss: 0.0103\n",
            "Train accuracy: 0.560\n",
            "Dev accuracy: 0.340\n",
            "Time elapsed (remaining): 11m 26s (26m 41s)\n",
            "Epoch #13:\n",
            "Loss: 0.0085\n",
            "Train accuracy: 0.592\n",
            "Dev accuracy: 0.310\n",
            "Time elapsed (remaining): 12m 18s (25m 33s)\n",
            "Epoch #14:\n",
            "Loss: 0.0094\n",
            "Train accuracy: 0.614\n",
            "Dev accuracy: 0.340\n",
            "Time elapsed (remaining): 13m 10s (24m 28s)\n",
            "Epoch #15:\n",
            "Loss: 0.0090\n",
            "Train accuracy: 0.596\n",
            "Dev accuracy: 0.350\n",
            "Time elapsed (remaining): 14m 3s (23m 25s)\n",
            "Epoch #16:\n",
            "Loss: 0.0087\n",
            "Train accuracy: 0.628\n",
            "Dev accuracy: 0.370\n",
            "Time elapsed (remaining): 14m 56s (22m 25s)\n",
            "Epoch #17:\n",
            "Loss: 0.0071\n",
            "Train accuracy: 0.706\n",
            "Dev accuracy: 0.410\n",
            "Time elapsed (remaining): 15m 49s (21m 24s)\n",
            "Epoch #18:\n",
            "Loss: 0.0082\n",
            "Train accuracy: 0.502\n",
            "Dev accuracy: 0.280\n",
            "Time elapsed (remaining): 16m 41s (20m 23s)\n",
            "Epoch #19:\n",
            "Loss: 0.0103\n",
            "Train accuracy: 0.606\n",
            "Dev accuracy: 0.380\n",
            "Time elapsed (remaining): 17m 33s (19m 24s)\n",
            "Epoch #20:\n",
            "Loss: 0.0076\n",
            "Train accuracy: 0.700\n",
            "Dev accuracy: 0.420\n",
            "Time elapsed (remaining): 18m 25s (18m 25s)\n",
            "Epoch #21:\n",
            "Loss: 0.0057\n",
            "Train accuracy: 0.680\n",
            "Dev accuracy: 0.390\n",
            "Time elapsed (remaining): 19m 16s (17m 26s)\n",
            "Epoch #22:\n",
            "Loss: 0.0081\n",
            "Train accuracy: 0.570\n",
            "Dev accuracy: 0.360\n",
            "Time elapsed (remaining): 20m 8s (16m 28s)\n",
            "Epoch #23:\n",
            "Loss: 0.0086\n",
            "Train accuracy: 0.618\n",
            "Dev accuracy: 0.430\n",
            "Time elapsed (remaining): 20m 58s (15m 30s)\n",
            "Epoch #24:\n",
            "Loss: 0.0056\n",
            "Train accuracy: 0.708\n",
            "Dev accuracy: 0.420\n",
            "Time elapsed (remaining): 21m 49s (14m 32s)\n",
            "Epoch #25:\n",
            "Loss: 0.0052\n",
            "Train accuracy: 0.632\n",
            "Dev accuracy: 0.380\n",
            "Time elapsed (remaining): 22m 39s (13m 35s)\n",
            "Epoch #26:\n",
            "Loss: 0.0080\n",
            "Train accuracy: 0.566\n",
            "Dev accuracy: 0.240\n",
            "Time elapsed (remaining): 23m 30s (12m 39s)\n",
            "Epoch #27:\n",
            "Loss: 0.0140\n",
            "Train accuracy: 0.578\n",
            "Dev accuracy: 0.260\n",
            "Time elapsed (remaining): 24m 23s (11m 44s)\n",
            "Epoch #28:\n",
            "Loss: 0.0080\n",
            "Train accuracy: 0.686\n",
            "Dev accuracy: 0.350\n",
            "Time elapsed (remaining): 25m 15s (10m 49s)\n",
            "Epoch #29:\n",
            "Loss: 0.0064\n",
            "Train accuracy: 0.690\n",
            "Dev accuracy: 0.390\n",
            "Time elapsed (remaining): 26m 8s (9m 54s)\n",
            "Epoch #30:\n",
            "Loss: 0.0052\n",
            "Train accuracy: 0.732\n",
            "Dev accuracy: 0.450\n",
            "Time elapsed (remaining): 27m 0s (9m 0s)\n",
            "Epoch #31:\n",
            "Loss: 0.0037\n",
            "Train accuracy: 0.756\n",
            "Dev accuracy: 0.410\n",
            "Time elapsed (remaining): 27m 52s (8m 5s)\n",
            "Epoch #32:\n",
            "Loss: 0.0033\n",
            "Train accuracy: 0.798\n",
            "Dev accuracy: 0.440\n",
            "Time elapsed (remaining): 28m 44s (7m 11s)\n",
            "Epoch #33:\n",
            "Loss: 0.0049\n",
            "Train accuracy: 0.546\n",
            "Dev accuracy: 0.290\n",
            "Time elapsed (remaining): 29m 34s (6m 16s)\n",
            "Epoch #34:\n",
            "Loss: 0.0058\n",
            "Train accuracy: 0.774\n",
            "Dev accuracy: 0.460\n",
            "Time elapsed (remaining): 30m 25s (5m 22s)\n",
            "Epoch #35:\n",
            "Loss: 0.0060\n",
            "Train accuracy: 0.724\n",
            "Dev accuracy: 0.420\n",
            "Time elapsed (remaining): 31m 16s (4m 28s)\n",
            "Epoch #36:\n",
            "Loss: 0.0126\n",
            "Train accuracy: 0.690\n",
            "Dev accuracy: 0.440\n",
            "Time elapsed (remaining): 32m 6s (3m 34s)\n",
            "Epoch #37:\n",
            "Loss: 0.0076\n",
            "Train accuracy: 0.626\n",
            "Dev accuracy: 0.390\n",
            "Time elapsed (remaining): 32m 57s (2m 40s)\n",
            "Epoch #38:\n",
            "Loss: 0.0052\n",
            "Train accuracy: 0.796\n",
            "Dev accuracy: 0.460\n",
            "Time elapsed (remaining): 33m 48s (1m 46s)\n",
            "Epoch #39:\n",
            "Loss: 0.0029\n",
            "Train accuracy: 0.798\n",
            "Dev accuracy: 0.450\n",
            "Time elapsed (remaining): 34m 39s (0m 53s)\n",
            "Epoch #40:\n",
            "Loss: 0.0033\n",
            "Train accuracy: 0.776\n",
            "Dev accuracy: 0.420\n",
            "Time elapsed (remaining): 35m 30s (0m 0s)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYOx52MBxLAu",
        "colab_type": "text"
      },
      "source": [
        "## Attention Seq2seq Model with Copying\n",
        "As we saw in class, we can still improve upon the attention model. This can be done by adding a 'copying' mechanism, which could be viewed as a variant on pointer networks ([Vinyals et al, 2015](https://arxiv.org/abs/1506.03134)). Before implementing this model, we suggest that you review slides [52-61](https://www.cs.tau.ac.il/~joberant/teaching/nlp_fall_2019_2020/files/08_seq2seq.pdf#page=52) from the seq2seq lecture slides.\n",
        "\n",
        "As with the regular attention model, we will use the same encoder, and improve upon the decoder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YQTmTP_0luQ",
        "colab_type": "text"
      },
      "source": [
        "### Question 3.1\n",
        "Implement the `forward` method of `DecoderAttentionWithCopying`. You can copy parts of your code from the `forward` method of `DecoderAttention`.\n",
        " As in the regular attention model and even more so, there is no single canonical implementation of attention with copying in seq2seq. You can take inspiration from the class slides, from section 3.2 of Data Recombination for Neural Semantic Parsing [(Jia & Liang, 2016)](https://stanford.edu/~robinjia/pdf/jia2016recombination.pdf), or from any source of your choosing.\n",
        " \n",
        "Unlike the previous two decoders, here you can also add define additional weights/parameters in the `__init__`, in case you find it beneficial to your model.\n",
        "\n",
        "In addition, feel free to use `get_index_from_parallel_index` from your vocab object. You can assume the call `vocab_logical.set_parallel_vocab(vocab_natural)` was already made.\n",
        "\n",
        "\n",
        "Don't forget to address the `evaluation_mode` parameter, as the input to `GRUCell` could depend on whether we are training or evaluating. It is your choice if and how to use teacher forcing during training, but at least some usage of teacher forcing is highly recommended."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoSaTgWF4etu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderAttentionWithCopying(DecoderAttention):\n",
        "    def __init__(self, input_size, hidden_size, vocab, enc_hidden_size, **kwargs):\n",
        "        super().__init__(input_size, hidden_size, vocab, enc_hidden_size, **kwargs)\n",
        "\n",
        "        self.uses_copying = True\n",
        "\n",
        "        # PLACE TO ADD ADDITIONAL WEIGHTS (optional)\n",
        "\n",
        "        # ------------------------------------------\n",
        "\n",
        "    def forward(self, targets, h, enc_outputs, enc_input, evaluation_mode=False):\n",
        "\n",
        "        ### YOUR CODE HERE\n",
        "        raise NotImplementedError\n",
        "        ### --------------\n",
        "        return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOTfWXDQ5Okd",
        "colab_type": "text"
      },
      "source": [
        "### Question 3.2\n",
        "In addition to the new decoder, a change in `train_single_example` is also required, as now `criterion_target` should not be composed solely from `target_tensor`. Also, note that with `DecoderAttentionWithCopying` we use the [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/nn.html#bcewithlogitsloss) loss criterion (see later in notebook for details).\n",
        "\n",
        "Implement the `if dec.uses_copying:` clause of `train_single_example`.\n",
        "\n",
        "In general this part should help the loss function (`criterion`) understand what tokens from the input (natural sentence) are desirable for copying (in addition to the actual target token from the query string). This is done by defining `criterion_target` accordingly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O85tAjNx-Y8g",
        "colab_type": "text"
      },
      "source": [
        "### Question 3.3\n",
        "\n",
        "Finally, we need add code in `evaluate`. Implement the `if dec.uses_copying:` clause of `evaluate`.\n",
        "\n",
        "This code should enable the model to:\n",
        "* Decode tokens from the input natural sentence (as well as from the query string, as was done until now).\n",
        "* Copy input tokens that do not exist in our vocabulary.\n",
        "\n",
        "This question is quite open ended, so feel free to experiment, as long as your code follows the two guidelines above.\n",
        "\n",
        "For simplicity, we added below a set of all the words that are entities (i.e worth considering copying) and occur in both the natural sentences and the the query strings. This set is based on the words from the training set and the dev set, as well as from the hidden test set.\n",
        "\n",
        "You may add additional functions/code to be used in the `if dec.uses_copying:` clause of `evaluate` if you wish.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IjgrryJFaaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in practice, entities are probably decduced by some pretrained NER model\n",
        "all_entities = {\n",
        "    'rochester', 'kentucky', 'potomac', 'georgia', 'boulder', 'missouri', 'mississippi',\n",
        "    'sacramento', 'island', 'mount', 'houston', 'guadalupe', 'baton', 'north', 'spokane', 'salem',\n",
        "    'alabama', 'utah', 'erie', 'scotts', 'death', 'springfield', 'idaho', 'ohio', 'francisco',\n",
        "    'valley', 'jose', 'rio', 'new', 'chicago', 'florida', 'diego', 'indiana', 'detroit', 'montana',\n",
        "    'seattle', 'south', 'wyoming', 'texas', 'alaska', 'dakota', 'orleans', 'minnesota', 'riverside',\n",
        "    'delaware', 'plano', 'pittsburgh', 'hampshire', 'california', 'flint', 'nevada', 'west',\n",
        "    'massachusetts', 'york', 'illinois', 'me', 'oregon', 'mckinley', 'tucson', 'chattahoochee',\n",
        "    'des', 'arizona', 'michigan', 'maine', 'maryland', 'rhode', 'kalamazoo', 'tennessee', 'hawaii',\n",
        "    'virginia', 'salt', 'atlanta', 'austin', 'miami', 'antonio', 'carolina', 'san', 'durham',\n",
        "    'jersey', 'colorado', 'indianapolis', 'dover', 'vermont', 'albany', 'rouge', 'kansas', 'usa',\n",
        "    'grande', 'red', 'pennsylvania', 'nebraska', 'wayne', 'washington', 'tempe', 'mexico',\n",
        "    'montgomery', 'platte', 'whitney', 'arkansas', 'fort', 'oklahoma', 'boston', 'dallas',\n",
        "    'portland', 'louisiana', 'wisconsin', 'minneapolis', 'denver', 'peak', 'moines', 'dc',\n",
        "    'columbus', 'iowa'\n",
        "}\n",
        "\n",
        "def is_entity(token):\n",
        "    return token in all_entities\n",
        "\n",
        "\n",
        "# PLACE TO ADD OPTIONAL ADDITIONAL CODE TO BE USED IN THE COPYING CLAUSE OF `evaluate`\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------------\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKhXuu5mFpo2",
        "colab_type": "text"
      },
      "source": [
        "### Testing Question 3\n",
        "To test your implementation of the attention model with copying, you can run the following cell. Note that we expect a dev accuracy of at least 45 sometime until epoch 40 (could be a lot earlier), **as well as at least of couple of points better than the regular attention model**. Your code will be run with several initial seeds, and therefore the 45 dev accuracy and the slight improvement over the regular attention model are expected on average.  \n",
        "Use the `BCEWithLogitsLoss` criterion.\n",
        "\n",
        "To compare implementations during debugging, you can use the `set_random_seeds()` function.\n",
        "\n",
        "**Add the output figure, `ROOT/figures/attention_with_copying_decoder.png`, to the submission zip!** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3XpCNNvGQqz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "29d6756d-07b9-4e3c-9603-82c6317f7462"
      },
      "source": [
        "print('--- Training Copying Model ---')\n",
        "set_random_seeds()\n",
        "vocab_logical.set_parallel_vocab(vocab_natural)\n",
        "enc3 = EncoderRNN(enc_input_size, enc_hidden_size, vocab_natural).to(device)\n",
        "dec3 = DecoderAttentionWithCopying(dec_input_size, dec_hidden_size, vocab_logical, enc_hidden_size).to(device)\n",
        "criterion3 = nn.BCEWithLogitsLoss()\n",
        "\n",
        "losses3, train_accs3, dev_accs3 = train(n_epochs, train_sentences, dev_sentences,\n",
        "                                        enc3, dec3, criterion3)\n",
        "plot_accuracies(train_accs3, dev_accs3, 'attention_with_copying_decoder')\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Training Copying Model ---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-508055b655fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m losses3, train_accs3, dev_accs3 = train(n_epochs, train_sentences, dev_sentences,\n\u001b[0;32m----> 9\u001b[0;31m                                         enc3, dec3, criterion3)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplot_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_accs3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_accs3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attention_with_copying_decoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-9560740eed6b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(n_epochs, train_set, dev_set, enc, dec, criterion, patience, save, print_sentences)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             loss = train_single_example(input_tensor, target_tensor, enc, dec,\n\u001b[0;32m---> 24\u001b[0;31m                                         encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-96f4a17e1ab5>\u001b[0m in \u001b[0;36mtrain_single_example\u001b[0;34m(input_tensor, target_tensor, enc, dec, enc_optimizer, dec_optimizer, criterion)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdecoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_h_m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_copying\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-80bc8f484a35>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, targets, h, enc_outputs, enc_input, evaluation_mode)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m### YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m### --------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxddxo_72LXX",
        "colab_type": "text"
      },
      "source": [
        "## On Reaching State of the Art Results\n",
        "In Data Recombination for Neural Semantic Parsing [(Jia & Liang, 2016)](https://stanford.edu/~robinjia/pdf/jia2016recombination.pdf#page=7), the results were much better than our model - 85.0 (and even higher with some additional methods they introduced). A substantial part of this gap could be reduced by applying the rather simple suggestions from the [Improving the Simple Model](https://colab.research.google.com/drive/1LuVweHOfi3qQkipZHTki9cyI_TOcRQyQ#scrollTo=Exq6p6XtXJvH&line=2&uniqifier=1) cell. So when you are confident that your implementation is working, feel free to see how close you can get to these impressive results!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoIdzhjmnVQ_",
        "colab_type": "text"
      },
      "source": [
        "## Submission Instructions:\n",
        "1. **Restart the kernel** (in the menubar, select Runtime$\\rightarrow$Restart runtime)\n",
        "2. **Run all cells** (in the menubar, select Runtime$\\rightarrow$Run All).\n",
        "3. **Download the notebook** (in the menubar, select File$\\rightarrow$Download .ipynb)\n",
        "4. **Add the downloaded notebook (.ipynb file) to the submission zip**.\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE`."
      ]
    }
  ]
}